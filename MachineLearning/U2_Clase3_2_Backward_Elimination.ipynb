{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have a dataset of 50 startups with their profits, location and different types of expenses. We would like to create a model to predict their profits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### First, we need to download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0  165349.20       136897.80        471784.10    New York  192261.83\n",
       "1  162597.70       151377.59        443898.53  California  191792.06\n",
       "2  153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3  144372.41       118671.85        383199.62    New York  182901.99\n",
       "4  142107.34        91391.77        366168.42     Florida  166187.94"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the dataset\n",
    "dataset = pd.read_csv('50_Startups.csv')\n",
    "dataset.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 4].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['New York', 'California', 'Florida', 'New York', 'Florida',\n",
       "       'New York', 'California', 'Florida', 'New York', 'California',\n",
       "       'Florida', 'California', 'Florida', 'California', 'Florida',\n",
       "       'New York', 'California', 'New York', 'Florida', 'New York',\n",
       "       'California', 'New York', 'Florida', 'Florida', 'New York',\n",
       "       'California', 'Florida', 'New York', 'Florida', 'New York',\n",
       "       'Florida', 'New York', 'California', 'Florida', 'California',\n",
       "       'New York', 'Florida', 'California', 'New York', 'California',\n",
       "       'California', 'Florida', 'California', 'New York', 'California',\n",
       "       'New York', 'Florida', 'California', 'New York', 'California'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Since we have categorical data, we need to encode it somehow into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "X[:, 3] = labelencoder.fit_transform(X[:, 3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 2, 1, 2, 0, 1, 2, 0, 1, 0, 1, 0, 1, 2, 0, 2, 1, 2, 0, 2,\n",
       "       1, 1, 2, 0, 1, 2, 1, 2, 1, 2, 0, 1, 0, 2, 1, 0, 2, 0, 0, 1, 0, 2,\n",
       "       0, 2, 1, 0, 2, 0], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:371: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/_encoders.py:392: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "onehotencoder = OneHotEncoder(categorical_features = [3])\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 54)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "        1.3689780e+05, 4.7178410e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "        0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.5137759e+05, 4.4389853e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "        1.0114555e+05, 4.0793454e+05]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoiding the Dummy Variable\n",
    "X = X[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 53)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.3689780e+05,\n",
       "        4.7178410e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "        1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.5137759e+05,\n",
       "        4.4389853e+05],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        0.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0114555e+05,\n",
       "        4.0793454e+05]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Multiple Linear Regression to the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x12bb39668>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_pred, y_test, color = 'red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([201181.70644051,   8642.38329355,  77587.21842654,   9734.38039107,\n",
       "        98210.69676771, 159830.04916283,  -5437.5086903 , 151590.23401124,\n",
       "       119339.78233674,  68741.30463651])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([103282.38, 144259.4 , 146121.95,  77798.83, 191050.39, 105008.31,\n",
       "        81229.06,  97483.56, 110352.25, 166187.94])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Is it necessary to include all the variables??\n",
    "#### What if we have thousand variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's reduce the number of Variables using Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.584</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Mar 2019</td> <th>  Prob (F-statistic):</th>  <td>0.0496</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:32:28</td>     <th>  Log-Likelihood:    </th> <td> -595.48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1201.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1211.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.849e+04</td> <td> 2796.080</td> <td>   20.917</td> <td> 0.000</td> <td> 5.29e+04</td> <td> 6.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> 5.849e+04</td> <td> 2796.080</td> <td>   20.917</td> <td> 0.000</td> <td> 5.29e+04</td> <td> 6.41e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td> -8.13e+04</td> <td> 3.83e+04</td> <td>   -2.121</td> <td> 0.039</td> <td>-1.59e+05</td> <td>-4083.603</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>-5.205e+04</td> <td> 3.83e+04</td> <td>   -1.358</td> <td> 0.181</td> <td>-1.29e+05</td> <td> 2.52e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>-6.748e+04</td> <td> 3.83e+04</td> <td>   -1.760</td> <td> 0.085</td> <td>-1.45e+05</td> <td> 9733.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>-4.721e+04</td> <td> 3.83e+04</td> <td>   -1.232</td> <td> 0.225</td> <td>-1.24e+05</td> <td>    3e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.208</td> <th>  Durbin-Watson:     </th> <td>   0.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.547</td> <th>  Jarque-Bera (JB):  </th> <td>   0.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.012</td> <th>  Prob(JB):          </th> <td>   0.786</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.480</td> <th>  Cond. No.          </th> <td>4.80e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 4.34e-32. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.187\n",
       "Model:                            OLS   Adj. R-squared:                  0.115\n",
       "Method:                 Least Squares   F-statistic:                     2.584\n",
       "Date:                Wed, 13 Mar 2019   Prob (F-statistic):             0.0496\n",
       "Time:                        11:32:28   Log-Likelihood:                -595.48\n",
       "No. Observations:                  50   AIC:                             1201.\n",
       "Df Residuals:                      45   BIC:                             1211.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.849e+04   2796.080     20.917      0.000    5.29e+04    6.41e+04\n",
       "x1          5.849e+04   2796.080     20.917      0.000    5.29e+04    6.41e+04\n",
       "x2          -8.13e+04   3.83e+04     -2.121      0.039   -1.59e+05   -4083.603\n",
       "x3         -5.205e+04   3.83e+04     -1.358      0.181   -1.29e+05    2.52e+04\n",
       "x4         -6.748e+04   3.83e+04     -1.760      0.085   -1.45e+05    9733.737\n",
       "x5         -4.721e+04   3.83e+04     -1.232      0.225   -1.24e+05       3e+04\n",
       "==============================================================================\n",
       "Omnibus:                        1.208   Durbin-Watson:                   0.460\n",
       "Prob(Omnibus):                  0.547   Jarque-Bera (JB):                0.481\n",
       "Skew:                          -0.012   Prob(JB):                        0.786\n",
       "Kurtosis:                       3.480   Cond. No.                     4.80e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 4.34e-32. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the optimal model using Backward Elimination\n",
    "import statsmodels.formula.api as sm\n",
    "X = np.append(arr = np.ones((50, 1)).astype(int), values = X, axis = 1)\n",
    "#we need the above step because OLS from statsmodel does not include the intercept\n",
    "List_aux = [0, 1, 2, 3, 4, 5]\n",
    "X_opt = X[:, List_aux]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To do it in a programatic way you need to select the variable with the highes p-value and exclude it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.14795964e-25 8.14795964e-25 3.94990217e-02 1.81360883e-01\n",
      " 8.51680550e-02 2.24519382e-01]\n"
     ]
    }
   ],
   "source": [
    "print(regressor_OLS.pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indx=np.argmax(regressor_OLS.pvalues)\n",
    "List_aux.pop(indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### But here we will do it manually in order to see what is going on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.809</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Mar 2019</td> <th>  Prob (F-statistic):</th>  <td> 0.159</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:35:02</td>     <th>  Log-Likelihood:    </th> <td> -597.87</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1204.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1211.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 5.762e+04</td> <td> 2869.394</td> <td>   20.082</td> <td> 0.000</td> <td> 5.18e+04</td> <td> 6.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> 5.762e+04</td> <td> 2869.394</td> <td>   20.082</td> <td> 0.000</td> <td> 5.18e+04</td> <td> 6.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-5.032e+04</td> <td> 3.98e+04</td> <td>   -1.266</td> <td> 0.212</td> <td> -1.3e+05</td> <td> 2.97e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>-6.575e+04</td> <td> 3.98e+04</td> <td>   -1.654</td> <td> 0.105</td> <td>-1.46e+05</td> <td> 1.43e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>-4.548e+04</td> <td> 3.98e+04</td> <td>   -1.144</td> <td> 0.259</td> <td>-1.26e+05</td> <td> 3.45e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.765</td> <th>  Durbin-Watson:     </th> <td>   0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.682</td> <th>  Jarque-Bera (JB):  </th> <td>   0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.073</td> <th>  Prob(JB):          </th> <td>   0.901</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.281</td> <th>  Cond. No.          </th> <td>4.94e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 4.1e-32. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.106\n",
       "Model:                            OLS   Adj. R-squared:                  0.047\n",
       "Method:                 Least Squares   F-statistic:                     1.809\n",
       "Date:                Wed, 13 Mar 2019   Prob (F-statistic):              0.159\n",
       "Time:                        11:35:02   Log-Likelihood:                -597.87\n",
       "No. Observations:                  50   AIC:                             1204.\n",
       "Df Residuals:                      46   BIC:                             1211.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       5.762e+04   2869.394     20.082      0.000    5.18e+04    6.34e+04\n",
       "x1          5.762e+04   2869.394     20.082      0.000    5.18e+04    6.34e+04\n",
       "x2         -5.032e+04   3.98e+04     -1.266      0.212    -1.3e+05    2.97e+04\n",
       "x3         -6.575e+04   3.98e+04     -1.654      0.105   -1.46e+05    1.43e+04\n",
       "x4         -4.548e+04   3.98e+04     -1.144      0.259   -1.26e+05    3.45e+04\n",
       "==============================================================================\n",
       "Omnibus:                        0.765   Durbin-Watson:                   0.190\n",
       "Prob(Omnibus):                  0.682   Jarque-Bera (JB):                0.209\n",
       "Skew:                          -0.073   Prob(JB):                        0.901\n",
       "Kurtosis:                       3.281   Cond. No.                     4.94e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 4.1e-32. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_opt = X[:, List_aux]\n",
    "X_opt = X[:, [0,1,3,4,5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.047</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.809</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Mar 2019</td> <th>  Prob (F-statistic):</th>  <td> 0.159</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:35:07</td>     <th>  Log-Likelihood:    </th> <td> -597.87</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1204.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1211.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 1.152e+05</td> <td> 5738.788</td> <td>   20.082</td> <td> 0.000</td> <td> 1.04e+05</td> <td> 1.27e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-5.032e+04</td> <td> 3.98e+04</td> <td>   -1.266</td> <td> 0.212</td> <td> -1.3e+05</td> <td> 2.97e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-6.575e+04</td> <td> 3.98e+04</td> <td>   -1.654</td> <td> 0.105</td> <td>-1.46e+05</td> <td> 1.43e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>-4.548e+04</td> <td> 3.98e+04</td> <td>   -1.144</td> <td> 0.259</td> <td>-1.26e+05</td> <td> 3.45e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.765</td> <th>  Durbin-Watson:     </th> <td>   0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.682</td> <th>  Jarque-Bera (JB):  </th> <td>   0.209</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.073</td> <th>  Prob(JB):          </th> <td>   0.901</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.281</td> <th>  Cond. No.          </th> <td>    7.30</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.106\n",
       "Model:                            OLS   Adj. R-squared:                  0.047\n",
       "Method:                 Least Squares   F-statistic:                     1.809\n",
       "Date:                Wed, 13 Mar 2019   Prob (F-statistic):              0.159\n",
       "Time:                        11:35:07   Log-Likelihood:                -597.87\n",
       "No. Observations:                  50   AIC:                             1204.\n",
       "Df Residuals:                      46   BIC:                             1211.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       1.152e+05   5738.788     20.082      0.000    1.04e+05    1.27e+05\n",
       "x1         -5.032e+04   3.98e+04     -1.266      0.212    -1.3e+05    2.97e+04\n",
       "x2         -6.575e+04   3.98e+04     -1.654      0.105   -1.46e+05    1.43e+04\n",
       "x3         -4.548e+04   3.98e+04     -1.144      0.259   -1.26e+05    3.45e+04\n",
       "==============================================================================\n",
       "Omnibus:                        0.765   Durbin-Watson:                   0.190\n",
       "Prob(Omnibus):                  0.682   Jarque-Bera (JB):                0.209\n",
       "Skew:                          -0.073   Prob(JB):                        0.901\n",
       "Kurtosis:                       3.281   Cond. No.                         7.30\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:, [0, 3, 4, 5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.299</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Mar 2019</td> <th>  Prob (F-statistic):</th>  <td> 0.283</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:35:09</td>     <th>  Log-Likelihood:    </th> <td> -599.31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1205.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1210.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 1.139e+05</td> <td> 5782.556</td> <td>   19.693</td> <td> 0.000</td> <td> 1.02e+05</td> <td> 1.26e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-4.895e+04</td> <td> 4.05e+04</td> <td>   -1.209</td> <td> 0.233</td> <td> -1.3e+05</td> <td> 3.25e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-4.411e+04</td> <td> 4.05e+04</td> <td>   -1.090</td> <td> 0.281</td> <td>-1.26e+05</td> <td> 3.73e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.323</td> <th>  Durbin-Watson:     </th> <td>   0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.851</td> <th>  Jarque-Bera (JB):  </th> <td>   0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.058</td> <th>  Prob(JB):          </th> <td>   0.981</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.072</td> <th>  Cond. No.          </th> <td>    7.22</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.052\n",
       "Model:                            OLS   Adj. R-squared:                  0.012\n",
       "Method:                 Least Squares   F-statistic:                     1.299\n",
       "Date:                Wed, 13 Mar 2019   Prob (F-statistic):              0.283\n",
       "Time:                        11:35:09   Log-Likelihood:                -599.31\n",
       "No. Observations:                  50   AIC:                             1205.\n",
       "Df Residuals:                      47   BIC:                             1210.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       1.139e+05   5782.556     19.693      0.000    1.02e+05    1.26e+05\n",
       "x1         -4.895e+04   4.05e+04     -1.209      0.233    -1.3e+05    3.25e+04\n",
       "x2         -4.411e+04   4.05e+04     -1.090      0.281   -1.26e+05    3.73e+04\n",
       "==============================================================================\n",
       "Omnibus:                        0.323   Durbin-Watson:                   0.159\n",
       "Prob(Omnibus):                  0.851   Jarque-Bera (JB):                0.039\n",
       "Skew:                          -0.058   Prob(JB):                        0.981\n",
       "Kurtosis:                       3.072   Cond. No.                         7.22\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:, [0, 3, 5]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   1.404</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 13 Mar 2019</td> <th>  Prob (F-statistic):</th>  <td> 0.242</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:35:11</td>     <th>  Log-Likelihood:    </th> <td> -599.93</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1204.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1208.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  1.13e+05</td> <td> 5734.430</td> <td>   19.701</td> <td> 0.000</td> <td> 1.01e+05</td> <td> 1.25e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-4.805e+04</td> <td> 4.05e+04</td> <td>   -1.185</td> <td> 0.242</td> <td> -1.3e+05</td> <td> 3.35e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.115</td> <th>  Durbin-Watson:     </th> <td>   0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.944</td> <th>  Jarque-Bera (JB):  </th> <td>   0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.015</td> <th>  Prob(JB):          </th> <td>   0.996</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.949</td> <th>  Cond. No.          </th> <td>    7.15</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.028\n",
       "Model:                            OLS   Adj. R-squared:                  0.008\n",
       "Method:                 Least Squares   F-statistic:                     1.404\n",
       "Date:                Wed, 13 Mar 2019   Prob (F-statistic):              0.242\n",
       "Time:                        11:35:11   Log-Likelihood:                -599.93\n",
       "No. Observations:                  50   AIC:                             1204.\n",
       "Df Residuals:                      48   BIC:                             1208.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        1.13e+05   5734.430     19.701      0.000    1.01e+05    1.25e+05\n",
       "x1         -4.805e+04   4.05e+04     -1.185      0.242    -1.3e+05    3.35e+04\n",
       "==============================================================================\n",
       "Omnibus:                        0.115   Durbin-Watson:                   0.099\n",
       "Prob(Omnibus):                  0.944   Jarque-Bera (JB):                0.007\n",
       "Skew:                          -0.015   Prob(JB):                        0.996\n",
       "Kurtosis:                       2.949   Cond. No.                         7.15\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:, [0, 3]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The most important variable is R+D!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
